{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import itertools\n",
    "import numpy as np\n",
    "from scipy.cluster.vq import kmeans,vq\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib as plt\n",
    "from skimage import color\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.vq import vq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./ImageColorization-master/colorizer/gco_python/\")\n",
    "import pygco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_color_space(ncolors):\n",
    "    '''\n",
    "    Generates a palette, which maps the 8-bit color channels to bins in the discretized space.\n",
    "    Also generates colors, which is a list of all possible colors (a,b components) in this space.\n",
    "    '''\n",
    "    levels = int(np.floor(np.sqrt(ncolors)))\n",
    "    inds = np.arange(0, 256)\n",
    "    div = np.linspace(0, 255, levels+1)[1]\n",
    "    quantiz = np.int0(np.linspace(0, 255, levels))\n",
    "    color_levels = np.clip(np.int0(inds/div), 0, levels-1)\n",
    "    palette = quantiz[color_levels]\n",
    "    bins = np.unique(palette) #the actual color bins\n",
    "    colors = list(itertools.product(bins, bins)) #find all permutations of a/b bins\n",
    "    color_to_label_map = {c:i for i,c in enumerate(colors)} #this maps the color pair to the index of the color\n",
    "    label_to_color_map = dict(zip(color_to_label_map.values(),color_to_label_map.keys())) #takes a label and returns a,\n",
    "    return colors, color_to_label_map, label_to_color_map\n",
    "\n",
    "\n",
    "def train_kmeans(a, b, k):\n",
    "    pixel = np.squeeze(cv2.merge((a.flatten(),b.flatten()))).astype(float)\n",
    "    centroids= kmeans(pixel,k) \n",
    "    return centroids[0].shape[0]\n",
    "\n",
    "\n",
    "# K-means Color Space and Centroids\n",
    "def quantize_kmeans(a, b,ncolors):\n",
    "    w,h = np.shape(a)\n",
    "        \n",
    "    # reshape matrix\n",
    "    pixel = np.reshape((cv2.merge((a,b))),(w * h,2)).astype(float)\n",
    "    \n",
    "    # quantization\n",
    "    kmeans = KMeans(n_clusters=ncolors) \n",
    "    label=kmeans.fit(pixel)\n",
    "    \n",
    "    return label.labels_.reshape(w,h)\n",
    "\n",
    "def label_to_color_map_fun(a,b,ncolors):\n",
    "    \n",
    "    w,h = np.shape(a)\n",
    "    pixel = np.reshape((cv2.merge((a,b))),(w * h,2)).astype(float)\n",
    "    centroids,_ = kmeans(pixel,ncolors)\n",
    "    color_to_label_map = {c:i for i,c in enumerate([tuple(i) for i in centroids])}\n",
    "    label_to_color_map = dict(zip(color_to_label_map.values(),color_to_label_map.keys()))\n",
    "    \n",
    "    return label_to_color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterize(a, b,ncolors):\n",
    "    \n",
    "    levels = int(np.floor(np.sqrt(ncolors)))\n",
    "    inds = np.arange(0, 256)\n",
    "    div = np.linspace(0, 255, levels+1)[1]\n",
    "    quantiz = np.int0(np.linspace(0, 255, levels))\n",
    "    color_levels = np.clip(np.int0(inds/div), 0, levels-1)\n",
    "    palette = quantiz[color_levels]\n",
    "    bins = np.unique(palette) #the actual color bins\n",
    "    colors = list(itertools.product(bins, bins)) #find all permutations of a/b bins\n",
    "    \n",
    "    #this maps the color pair to the index of the color\n",
    "    color_to_label_map={c:i for i,c in enumerate(colors)}\n",
    "    label_to_color_map = dict(zip(color_to_label_map.values(),color_to_label_map.keys()))\n",
    "    a_quant = cv2.convertScaleAbs(palette[a])\n",
    "    b_quant = cv2.convertScaleAbs(palette[b])\n",
    "    return a_quant, b_quant,palette,color_to_label_map,label_to_color_map \n",
    "\n",
    "\n",
    "def train_svm(l,a,b,ntrain,ncolors,prob,gamma,cost,npca):\n",
    "    \n",
    "    #dimensions of image\n",
    "    m,n = l.shape \n",
    "    features = []\n",
    "    classes = []\n",
    "    numTrainingExamples = 0\n",
    "    colors_present = []\n",
    "    svm = [SVC(probability=prob, gamma=gamma, C=cost) for i in range(ncolors)]\n",
    "#     pca = PCA(npca)\n",
    "    \n",
    "    scaler = preprocessing.MinMaxScaler() \n",
    "    \n",
    "    label=quantize_kmeans(a, b,ncolors)\n",
    "    \n",
    "    for i in range(ntrain):\n",
    "        #choose random pixel in training image\n",
    "        x = int(np.random.uniform(n))\n",
    "        y = int(np.random.uniform(m))\n",
    "        \n",
    "        features.append(get_features(l, (x,y)))\n",
    "        classes.append(label[x,y])\n",
    "        numTrainingExamples = numTrainingExamples + 1\n",
    "        \n",
    "    # normalize columns\n",
    "    features =scaler.fit_transform(np.array(features))\n",
    "    classes = np.array(classes)\n",
    "        \n",
    "       \n",
    "    # reduce dimensionality\n",
    "#     features = pca.fit_transform(features)\n",
    "    \n",
    "    for i in range(ncolors):\n",
    "        if len(np.where(classes==i)[0])>0:\n",
    "            curr_class = (classes==i).astype(np.int32)\n",
    "            colors_present.append(i)\n",
    "            svm[i].fit(features,(classes==i).astype(np.int32))\n",
    "            \n",
    "    return colors_present,svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_surf(img, pos):\n",
    "    '''\n",
    "    Gets the SURF descriptor of img at pos = (x,y).\n",
    "    Assume img is a single channel image.\n",
    "    '''\n",
    "    octave2 = cv2.GaussianBlur(img, (0, 0), 1)\n",
    "    octave3 = cv2.GaussianBlur(img, (0, 0), 2)\n",
    "    kp = cv2.KeyPoint(pos[0], pos[1], SURF_WINDOW)\n",
    "    surf = cv2.xfeatures2d.SURF_create()\n",
    "    _, des1 = surf.compute(img, [kp])\n",
    "    _, des2 = surf.compute(octave2, [kp])\n",
    "    _, des3 = surf.compute(octave3, [kp])\n",
    "    return np.concatenate((des1[0], des2[0], des3[0]))\n",
    "\n",
    "def feature_dft(img, pos):\n",
    "    xlim = (max(pos[0] - windowSize,0), min(pos[0] + windowSize,img.shape[1]))\n",
    "    ylim = (max(pos[1] - windowSize,0), min(pos[1] + windowSize,img.shape[0]))\n",
    "    patch = img[ylim[0]:ylim[1],xlim[0]:xlim[1]]\n",
    "        \n",
    "    l = (2*windowSize + 1)**2\n",
    "    \n",
    "    #return all zeros for now if we're at the edge\n",
    "    if patch.shape[0]*patch.shape[1] != l:\n",
    "        return np.zeros(l)\n",
    "    return np.abs(np.fft(patch.flatten()))\n",
    "\n",
    "\n",
    "def feature_position(img, pos):\n",
    "    m,n = img.shape\n",
    "    x_pos = pos[0]/n\n",
    "    y_pos = pos[1]/m\n",
    "    \n",
    "    return np.array([x_pos, y_pos])\n",
    "            \n",
    "\n",
    "def get_features(img, pos):\n",
    "    intensity = np.array([img[pos[1], pos[0]]])\n",
    "    #position = feature_position(img, pos)\n",
    "    meanvar = np.array([getMean(img, pos), getVariance(img, pos)])\n",
    "    feat = np.concatenate((meanvar, feature_surf(img, pos), feature_dft(img, pos)))\n",
    "    return feat\n",
    "\n",
    "\n",
    "def getMean(img, pos):\n",
    "    ''' \n",
    "    Returns mean value over a windowed region around (x,y)\n",
    "    '''\n",
    "     \n",
    "    xlim = (max(pos[0] - windowSize,0), min(pos[0] + windowSize,img.shape[1]))\n",
    "    ylim = (max(pos[1] - windowSize,0), min(pos[1] + windowSize,img.shape[0]))\n",
    "    return np.mean(img[ylim[0]:ylim[1],xlim[0]:xlim[1]])\n",
    "\n",
    "        \n",
    "def getVariance(img, pos):\n",
    "    \n",
    "    xlim = (max(pos[0] - windowSize,0), min(pos[0] + windowSize,img.shape[1]))\n",
    "    ylim = (max(pos[1] - windowSize,0), min(pos[1] + windowSize,img.shape[0]))\n",
    "    \n",
    "    return np.var(img[ylim[0]:ylim[1],xlim[0]:xlim[1]])/1000\n",
    "\n",
    "# add\n",
    "def get_edges(img, blur_width=3):\n",
    "        img_blurred = cv2.GaussianBlur(img, (0, 0), blur_width)\n",
    "        vh = cv2.Sobel(img_blurred, -1, 1, 0)\n",
    "        vv = cv2.Sobel(img_blurred, -1, 0, 1)\n",
    "\n",
    "        #vh = vh/np.max(vh)\n",
    "        #vv = vv/np.max(vv)\n",
    "        \n",
    "        #v = np.sqrt(vv**2 + vh**2)\n",
    "\n",
    "        v = 0.5*vv + 0.5*vh\n",
    "#        print('max pre-normalize: %f'%np.amax(v))\n",
    "        #v = v/np.amax(v)\n",
    "        return v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SURF_WINDOW = 20\n",
    "DCT_WINDOW = 20\n",
    "windowSize = 10\n",
    "gridSpacing = 7\n",
    "\n",
    "img='./Train/train.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage import color \n",
    "def load_image(path):\n",
    "    '''\n",
    "    Read in a file and separate into L*a*b* channels\n",
    "    '''\n",
    "#     #read in original image\n",
    "    img = cv2.imread(path) \n",
    "    #convert to L*a*b* space and split into channels\n",
    "#     l, a, b = cv2.split(cv2.cvtColor(img, cv2.COLOR_BGR2LAB))\n",
    "    l, a, b = cv2.split(cv2.cvtColor(img, cv2.COLOR_RGB2LAB))\n",
    "\n",
    "    return l, a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncolors = 20\n",
    "l, a, b = load_image(img)\n",
    "print(l.shape,a.shape,b.shape)\n",
    "label_kmeans = quantize_kmeans(a, b, ncolors)\n",
    "label_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_present = [i for i in range(20)]\n",
    "colors_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_a = np.zeros((720,720))\n",
    "output_b = np.zeros((720,720))\n",
    "output_l = np.ones((720,720))*90\n",
    "for i in range(720):\n",
    "    for j in range(720):\n",
    "        a,b = label_to_color_map[colors_present[label_kmeans[i,j]]]\n",
    "        output_a[i,j] = a\n",
    "        output_b[i,j] = b\n",
    "        \n",
    "output_img = cv2.cvtColor(cv2.merge(( np.uint8(output_l), np.uint8(output_a), np.uint8(output_b))), cv2.COLOR_LAB2RGB)\n",
    "plt.imshow(output_img)\n",
    "# plt.imsave('output_img1.jpg',output_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncolors = 36\n",
    "ntrain = 3000\n",
    "# (l, a, b) = load_image(img)\n",
    "prob = False\n",
    "npca = 635\n",
    "gamma = 0.1\n",
    "cost = 5.0\n",
    "colors_present,svm = train_svm(l,a,b,\n",
    "                           ntrain = ntrain,\n",
    "                           ncolors = ncolors,\n",
    "                           prob = prob,\n",
    "                           gamma = gamma,\n",
    "                           cost = cost,\n",
    "                           npca = npca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_color_map = label_to_color_map_fun(a,b,ncolors)\n",
    "label_to_color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get edge\n",
    "code_book = array([[1.,2.,3.,4.]])\n",
    "features  = array([[1.5,2.5,3.5,4.5]])\n",
    "vq(features,code_book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_test_tmp = get_edges(img_test_file)\n",
    "img_test_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph cut\n",
    "def graphcut(colors_present, label_to_color_map, label_costs, g, l=100):\n",
    "    \n",
    "    num_classes = len(colors_present)\n",
    "\n",
    "    #calculate pariwise potiential costs (distance between color classes)\n",
    "    pairwise_costs = np.zeros((num_classes, num_classes))\n",
    "    for ii in range(num_classes):\n",
    "        for jj in range(num_classes):\n",
    "            c1 = np.array(label_to_color_map[ii])\n",
    "            c2 = np.array(label_to_color_map[jj])\n",
    "            pairwise_costs[ii,jj] = np.linalg.norm(c1-c2)\n",
    "\n",
    "    label_costs_int32 = (100*label_costs).astype('int32')\n",
    "    pairwise_costs_int32 = (l*pairwise_costs).astype('int32')\n",
    "    vv_int32 = g.astype('int32')\n",
    "    vh_int32 = g.astype('int32')\n",
    "\n",
    "    #vv_int32 = (1/np.clip(self.g,0.00001,10000)).astype('int32')\n",
    "    #vh_int32 = (1/np.clip(self.g,0.00001,10000)).astype('int32')\n",
    "\n",
    "    #perform graphcut optimization\n",
    "    new_labels = pygco.cut_simple_vh(label_costs_int32,\n",
    "                                     pairwise_costs_int32,\n",
    "                                     vv_int32, vh_int32,\n",
    "                                     n_iter=10, algorithm='swap') \n",
    "\n",
    "    #new_labels = pygco.cut_simple(label_costs_int32, pairwise_costs_int32, algorithm='swap')\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_costs = np.ones((720,720,20))\n",
    "g = np.zeros((720,720))\n",
    "graphcut(colors_present, label_to_color_map, label_costs, g = g, l=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colorize\n",
    "def colorize(colors_present,label_to_color_map, img, svm, skip=4, SAVE_OUTPUTS = False):\n",
    "    '''\n",
    "    -- colorizes a grayscale image, using the set of SVMs defined by train().\n",
    "\n",
    "    Returns:\n",
    "    -- ndarray(m,n,3): a mxn pixel RGB image\n",
    "    ''' \n",
    "    scaler = preprocessing.MinMaxScaler()   \n",
    "    m,n = img.shape\n",
    "\n",
    "    num_classified = 0\n",
    "    _,raw_output_a,raw_output_b = cv2.split(cv2.cvtColor(cv2.merge((img, img, img)), \n",
    "                                                         cv2.COLOR_RGB2LAB))\n",
    "\n",
    "    output_a = np.zeros(raw_output_a.shape)\n",
    "    output_b = np.zeros(raw_output_b.shape)\n",
    "\n",
    "    num_classes = len(colors_present)\n",
    "    label_costs = np.zeros((m,n,num_classes))\n",
    "\n",
    "    g = np.zeros(raw_output_a.shape)\n",
    "\n",
    "    count=0\n",
    "    for x in np.arange(0,n,skip):\n",
    "        for y in np.arange(0,m,skip):\n",
    "            \n",
    "            feat = get_features(img, (x,y)).reshape(1,-1)\n",
    "\n",
    "            #print \"Size, Pre-PCA\"\n",
    "            #print np.shape(feat)\n",
    "#             pca = PCA(npca)\n",
    "#             feat = pca.fit_transform(feat)\n",
    "            #print \"size, Post-PCA\"\n",
    "            #print np.shape(feat)\n",
    "\n",
    "            #sys.stdout.write('\\rcolorizing: %3.3f%%'%(np.min([100, 100*count*skip**2/(m*n)])))\n",
    "            #sys.stdout.flush()\n",
    "            count += 1\n",
    "\n",
    "            # Hard-but-correct way to get g\n",
    "            # self.g[y-int(skip/2):y+int(skip/2)+1,x-int(skip/2):x+int(skip/2)+1] = self.color_variation(feat)\n",
    "\n",
    "            #get margins to estimate confidence for each class\n",
    "            for i in range(num_classes):\n",
    "                cost = -1*svm[colors_present[i]].decision_function(feat)[0]\n",
    "                label_costs[y-int(skip/2):y+int(skip/2)+1,x-int(skip/2):x+int(skip/2)+1,i] = cost\n",
    "    #edges = self.get_edges(img)\n",
    "    #self.g = np.sqrt(edges[0]**2 + edges[1]**2)\n",
    "    g = get_edges(img)\n",
    "    #self.g = np.log10(self.g)\n",
    "\n",
    "    if SAVE_OUTPUTS:\n",
    "        #dump to pickle\n",
    "        print('saving to dump.dat')\n",
    "        fid = open('dump.dat', 'wb') \n",
    "        pickle.dump({'S': label_costs, 'g': g, 'cmap': label_to_color_map,\n",
    "                     'colors': colors_present}, fid)\n",
    "        fid.close()\n",
    "\n",
    "    #postprocess using graphcut optimization \n",
    "#     output_labels = graphcut(label_costs, l=graphcut_lambda)\n",
    "    output_labels = graphcut(colors_present, label_to_color_map, label_costs, g, l=100)\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            tmp = np.random.randint(num_classes, size=1)\n",
    "            a,b = label_to_color_map[colors_present[output_labels[i,j]]]\n",
    "            output_a[i,j] = a\n",
    "            output_b[i,j] = b\n",
    "            \n",
    "    output_img = cv2.cvtColor(cv2.merge((img, np.uint8(output_a), np.uint8(output_b))), cv2.COLOR_LAB2RGB)\n",
    "\n",
    "    return output_img, g, output_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_test = './Train/test.jpg'\n",
    "# l a b\n",
    "img_test_file = load_image(img_test)\n",
    "# img_test_file = cv2.imread(img_test) \n",
    "color_tmp = colorize(colors_present,label_to_color_map, img = img_test_file[0], svm = svm, skip=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(color_tmp[0])\n",
    "plt.show()\n",
    "# plt.imsave('color_tmp.jpg',color_tmp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_test_file.shape\n",
    "img_test = './Train/test.jpg'\n",
    "# img_test_file = load_image(img_test)[0]\n",
    "img_test_file = cv2.imread(img_test)\n",
    "print(img_test_file.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color_tmp[0].max(),color_tmp[0].min())\n",
    "gb = cv2.cvtColor( color_tmp[0], cv2.COLOR_Lab2RGB)\n",
    "print(gb.max(),gb.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gb.shape)\n",
    "plt.imsave('gb.jpg',gb)\n",
    "plt.imshow(gb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_grey = cv2.cvtColor( img_test_file, cv2.COLOR_LAB2RGB)\n",
    "test_grey = cv2.cvtColor( test_grey, cv2.COLOR_RGB2GRAY)\n",
    "plt.imshow(test_grey)\n",
    "plt.imsave('test_grey.jpg',test_grey)\n",
    "import matplotlib.image as mpimg\n",
    "img_test=mpimg.imread('./Train/test.jpg')\n",
    "lum_img = np.copy(img_test)\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n",
    "lum_img = rgb2gray(lum_img)\n",
    "plt.imshow(lum_img[:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features(HoG,Daisy)+GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from skimage.feature import hog\n",
    "from skimage.feature import daisy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# import train_label, train_image, test_image\n",
    "label999 = pd.read_csv('/Users/yuexuanhuang/Documents/GitHub/Spring2018-Project5-grp_10/output/GBM/train_label/label999.csv').iloc[:,1:]\n",
    "train_color = Image.open('/Users/yuexuanhuang/Documents/GitHub/Spring2018-Project5-grp_10/data/GBM/data-ach/7.jpg','r')\n",
    "label = label999\n",
    "test_color = Image.open('/Users/yuexuanhuang/Documents/GitHub/Spring2018-Project5-grp_10/data/GBM/Archive/img_1.png','r')\n",
    "\n",
    "# train model, predict, output\n",
    "def colorme(train_color, train_label, test_color):\n",
    "\n",
    "    train_color = train_color.convert('L') #makes it greyscale\n",
    "    train_gray = np.asarray(train_color.getdata(),dtype=np.float64).reshape((train_color.size[1],train_color.size[0]))\n",
    "    train_gray = np.asarray(train_gray,dtype=np.uint8) #if values still in range 0-255! \n",
    "    train_gray = Image.fromarray(train_gray,mode='L')\n",
    "    # train_gray.save('/Users/yuexuanhuang/Desktop/Proj_5/alpha2/gray/gray%s.png'%000)\n",
    "    \n",
    "    test_color = test_color.convert('L') #makes it greyscale\n",
    "    test_gray = np.asarray(test_color.getdata(),dtype=np.float64).reshape((test_color.size[1],test_color.size[0]))\n",
    "    test_gray = np.asarray(test_gray,dtype=np.uint8) #if values still in range 0-255! \n",
    "    test_gray = Image.fromarray(test_gray,mode='L')\n",
    "    # test_gray.save('/Users/yuexuanhuang/Desktop/Proj_5/alpha2/gray/gray%s.png'%001)\n",
    "    \n",
    "    # hog(256,256)\n",
    "    fd, hog_image = hog(train_gray, orientations=8, pixels_per_cell=(16, 16),\n",
    "                        cells_per_block=(1, 1), visualise=True)\n",
    "    \n",
    "    # daisy(256,256,3)\n",
    "    descs, descs_img = daisy(train_gray, step=180, radius=58, rings=2, histograms=6,\n",
    "                             orientations=8, visualize=True)\n",
    "    \n",
    "    train = pd.DataFrame(np.matrix(np.full((65536, 5), np.inf)))\n",
    "    train.columns = ['label', 'hog', 'daisy1', 'daisy2', 'daisy3']\n",
    "    for i in range(5):\n",
    "        if i == 0:\n",
    "            collect = train_label\n",
    "            for j in range(256):\n",
    "                for k in range(256):\n",
    "                    train.iloc[k+j*256, i] = collect.iloc[k,j]\n",
    "        \n",
    "        if i == 1:\n",
    "            collect = np.matrix(hog_image)\n",
    "            for j in range(256):\n",
    "                for k in range(256):\n",
    "                    train.iloc[k+j*256, i] = collect[k,j]\n",
    "                    \n",
    "        if i == 2:\n",
    "            collect = np.matrix(descs_img[:,:,0])\n",
    "            for j in range(256):\n",
    "                for k in range(256):\n",
    "                    train.iloc[k+j*256, i] = collect[k,j]\n",
    "                    \n",
    "        if i == 3:\n",
    "            collect = np.matrix(descs_img[:,:,1])\n",
    "            for j in range(256):\n",
    "                for k in range(256):\n",
    "                    train.iloc[k+j*256, i] = collect[k,j]\n",
    "                    \n",
    "        if i == 4:\n",
    "            collect = np.matrix(descs_img[:,:,2])\n",
    "            for j in range(256):\n",
    "                for k in range(256):\n",
    "                    train.iloc[k+j*256, i] = collect[k,j]\n",
    "                    \n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(train.iloc[:,1:], train.iloc[:,0], test_size = 0.3, random_state = 42)\n",
    "    clf = GradientBoostingClassifier()\n",
    "    clf.fit(train_features, train_labels)\n",
    "    # label_predict = clf.predict(test_features)\n",
    "    # np.mean(label_predict == test_labels)\n",
    "\n",
    "    # test\n",
    "    # hog(256,256)\n",
    "    fd, hog_image = hog(test_gray, orientations=8, pixels_per_cell=(16, 16),\n",
    "                        cells_per_block=(1, 1), visualise=True)\n",
    "    \n",
    "    # daisy(256,256,3)\n",
    "    descs, descs_img = daisy(test_gray, step=180, radius=58, rings=2, histograms=6,\n",
    "                             orientations=8, visualize=True)\n",
    "    \n",
    "    test = pd.DataFrame(np.matrix(np.full((65536, 4), np.inf)))\n",
    "    test.columns = ['hog', 'daisy1', 'daisy2', 'daisy3']\n",
    "    for i in range(4):\n",
    "        if i == 0:\n",
    "            collect = np.matrix(hog_image)\n",
    "            for j in range(256):\n",
    "                for k in range(256):\n",
    "                    test.iloc[k+j*256, i] = collect[k,j]\n",
    "                    \n",
    "        if i == 1:\n",
    "            collect = np.matrix(descs_img[:,:,0])\n",
    "            for j in range(256):\n",
    "                for k in range(256):\n",
    "                    test.iloc[k+j*256, i] = collect[k,j]\n",
    "                    \n",
    "        if i == 2:\n",
    "            collect = np.matrix(descs_img[:,:,1])\n",
    "            for j in range(256):\n",
    "                for k in range(256):\n",
    "                    test.iloc[k+j*256, i] = collect[k,j]\n",
    "                    \n",
    "        if i == 3:\n",
    "            collect = np.matrix(descs_img[:,:,2])\n",
    "            for j in range(256):\n",
    "                for k in range(256):\n",
    "                    test.iloc[k+j*256, i] = collect[k,j]\n",
    "    \n",
    "    test_predict = clf.predict(test)\n",
    "    test_label = pd.DataFrame(np.matrix(np.full((256, 256), np.inf)))\n",
    "    for i in range(256):\n",
    "        for j in range(256):\n",
    "            test_label.iloc[j,i] = test_predict[j+i*256]\n",
    "    \n",
    "    return test_label\n",
    "\n",
    "# get the test_label\n",
    "t_label = colorme(train_color = train_color, train_label = label, test_color = test_color)\n",
    "\n",
    "# import the image we need to colorize\n",
    "test_color = test_color.convert('L') #makes it greyscale\n",
    "test_gray = np.asarray(test_color.getdata(),dtype=np.float64).reshape((test_color.size[1],test_color.size[0]))\n",
    "test_gray = np.asarray(test_gray,dtype=np.uint8) #if values still in range 0-255! \n",
    "test_gray = Image.fromarray(test_gray,mode='L')\n",
    "test_gray.save('/Users/yuexuanhuang/Documents/GitHub/Spring2018-Project5-grp_10/output/GBM/gray/gray%s.png'%11)\n",
    "\n",
    "img = cv2.imread('/Users/yuexuanhuang/Documents/GitHub/Spring2018-Project5-grp_10/data/GBM/Archive/img_1.png')\n",
    "# img = cv2.resize(img, (256, 256)) \n",
    "l, a, b = cv2.split(cv2.cvtColor(img, cv2.COLOR_RGB2LAB))\n",
    "Lab_l = np.matrix(l)\n",
    "\n",
    "# define colorize function\n",
    "def show(standard, t_label, Lab_l):\n",
    "    Lab_a = np.matrix(np.full((256, 256), np.inf))\n",
    "    Lab_b = np.matrix(np.full((256, 256), np.inf))\n",
    "    for i in range(256):\n",
    "        for j in range(256):\n",
    "            Lab_a[i,j] = standard[np.int(t_label.iloc[i,j])][0]\n",
    "            Lab_b[i,j] = standard[np.int(t_label.iloc[i,j])][1]\n",
    "            \n",
    "    ar = np.zeros((256,256,3))\n",
    "    ar[:,:,0] = Lab_l / 2.55\n",
    "    ar[:,:,1] = Lab_a\n",
    "    ar[:,:,2] = Lab_b\n",
    "    rgb = skimage.color.lab2rgb(ar)\n",
    "    return rgb\n",
    "\n",
    "# show the colorful picture\n",
    "plt.imshow(show(standard, t_label, Lab_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB+Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import itertools\n",
    "import numpy as np\n",
    "from scipy.cluster.vq import kmeans,vq\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "import operator\n",
    "from functools import reduce\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "from skimage.feature import hog, daisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage import color \n",
    "def load_image(path):\n",
    "    '''\n",
    "    Read in a file and separate into L*a*b* channels\n",
    "    '''\n",
    "    #read in original image\n",
    "    img = cv2.imread(path) \n",
    "    l, a, b = cv2.split(cv2.cvtColor(img, cv2.COLOR_RGB2LAB))\n",
    "#     a, l, b = cv2.split(cv2.cvtColor(img, cv2.COLOR_RGB2HLS))\n",
    "\n",
    "\n",
    "    return l, a, b\n",
    "\n",
    "def quantize_kmeans(a, b,ncolors, npics):\n",
    "    lengthab = len(a) / npics\n",
    "            \n",
    "    # reshape matrix\n",
    "    pixel = np.reshape((cv2.merge((a,b))),(len(a),2)).astype(float)\n",
    "    \n",
    "    # quantization\n",
    "    kmeans = KMeans(n_clusters=ncolors) \n",
    "    label=kmeans.fit(pixel)\n",
    "    return label.labels_\n",
    "\n",
    "def label_to_color_map_fun(a,b,ncolors):\n",
    "    w,h = np.shape(a)\n",
    "    pixel = np.reshape((cv2.merge((a,b))),(w * h,2)).astype(float)\n",
    "    centroids,_ = kmeans(pixel,ncolors)\n",
    "    color_to_label_map = {c:i for i,c in enumerate([tuple(i) for i in centroids])}\n",
    "    label_to_color_map = dict(zip(color_to_label_map.values(),color_to_label_map.keys()))\n",
    "    return label_to_color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb(files,ncolors,num_class, npics):\n",
    "    \n",
    "    kmap_a=np.array([])\n",
    "    kmap_b=np.array([])\n",
    "    for f in files:\n",
    "        _,a,b = load_image(f)\n",
    "        kmap_a = np.concatenate([kmap_a, a.flatten()])\n",
    "        kmap_b = np.concatenate([kmap_b, b.flatten()])\n",
    "    w,h = np.shape(a)\n",
    "    label=quantize_kmeans(kmap_a, kmap_b, ncolors, npics)\n",
    "    \n",
    "    pixel=[]\n",
    "    for f in files:\n",
    "        l, a, b = load_image(f)\n",
    "        this_pixel = l.reshape(1,w*h).tolist()\n",
    "        pixel.append(this_pixel[0])\n",
    "\n",
    "    pixel = reduce(operator.add, pixel)\n",
    "\n",
    "    pixel_mat = np.array(pixel).reshape(npics*w*h,1)\n",
    "\n",
    "    dtrain = xgb.DMatrix(pixel_mat, label=label)\n",
    "    param = {'max_depth':10, 'eta':0.1, 'silent':1, 'objective':'multi:softmax', 'num_class':num_class}\n",
    "    num_round = 10\n",
    "    print('Begin xgb training')\n",
    "    bst = xgb.train(param, dtrain, num_round)\n",
    "    return bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(file):\n",
    "    test_color = Image.open(file,'r')\n",
    "    test_color = test_color.convert('L') #makes it greyscale\n",
    "    test_gray = np.asarray(test_color.getdata(),dtype=np.float64).reshape((test_color.size[1],test_color.size[0]))\n",
    "    test_gray = np.asarray(test_gray,dtype=np.uint8) #if values still in range 0-255! \n",
    "    test_gray = Image.fromarray(test_gray,mode='L')\n",
    "    \n",
    "    # l(256,256)\n",
    "    l, a, b = load_image(file)\n",
    "    w,h = np.shape(a)\n",
    "    # hog(256,256)\n",
    "    fd, hog_image = hog(test_gray, orientations=8, pixels_per_cell=(16, 16),\n",
    "                        cells_per_block=(1, 1), visualise=True)\n",
    "    # daisy(256,256,3)\n",
    "    descs, descs_img = daisy(test_gray, step=180, radius=58, rings=2, histograms=6,\n",
    "                             orientations=8, visualize=True)\n",
    "                             \n",
    "    # l only\n",
    "    feature = np.zeros((w*h,1))\n",
    "    feature[:,0] = l.reshape(1,w*h)[0]\n",
    "    \n",
    "    return(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_fea(files,ncolors,num_class, npics):\n",
    "    \n",
    "    kmap_a=np.array([])\n",
    "    kmap_b=np.array([])\n",
    "    \n",
    "\n",
    "    for f in files:\n",
    "        _,a,b = load_image(f)\n",
    "        kmap_a = np.concatenate([kmap_a, a.flatten()])\n",
    "        kmap_b = np.concatenate([kmap_b, b.flatten()])\n",
    "\n",
    "    label=quantize_kmeans(kmap_a, kmap_b, ncolors, npics)\n",
    "    w,h = np.shape(a)\n",
    "        \n",
    "    pixel_feature = np.zeros(shape=(w*h*npics,1))\n",
    "    \n",
    "\n",
    "    \n",
    "    for ind,f in enumerate(files):\n",
    "        feature = get_feature(f)\n",
    "        pixel_feature[(w*h*ind):(w*h*(ind+1)),:] = feature\n",
    "\n",
    "#     pixel_mat = np.array(pixel).reshape(npics*256*256,1)\n",
    "\n",
    "    dtrain = xgb.DMatrix(pixel_feature, label=label)\n",
    "    param = {'max_depth':10, 'eta':0.1, 'silent':1, 'objective':'multi:softmax', 'num_class':num_class}\n",
    "    num_round = 10\n",
    "    print('Begin xgb training')\n",
    "    bst = xgb.train(param, dtrain, num_round)\n",
    "    return bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_xgb_fea(file,xgb_model):\n",
    "        \n",
    "    pixel_feature = get_feature(file)\n",
    "\n",
    "    dtest=xgb.DMatrix(pixel_feature)\n",
    "    preds = xgb_fit.predict(dtest)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load images\n",
    "folder_dir = './girl/'\n",
    "train_dir = []\n",
    "\n",
    "for filename in os.listdir(folder_dir):\n",
    "    if filename.startswith('.') or \\\n",
    "    filename.startswith('predict') or \\\n",
    "    filename.startswith('gray'): \n",
    "        continue\n",
    "    train_dir.append(folder_dir + filename)\n",
    "\n",
    "# train_dir = ['WechatIMG1667.jpeg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncolors = 16\n",
    "kmap_a=np.array([])\n",
    "kmap_b=np.array([])\n",
    "for f in train_dir:\n",
    "    _,a,b = load_image(f)\n",
    "    kmap_a = np.concatenate([kmap_a, a.flatten()])\n",
    "    kmap_b = np.concatenate([kmap_b, b.flatten()])\n",
    "h,w = np.shape(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npics = len(train_dir) # number of train image\n",
    "kmap_a = kmap_a.reshape(npics*w*h,1)\n",
    "kmap_b = kmap_b.reshape(npics*w*h,1)\n",
    "label_to_color_map = label_to_color_map_fun(kmap_a,kmap_b,ncolors)\n",
    "print(len(label_to_color_map))\n",
    "ncolors = len(label_to_color_map) # update ncolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_fit = train_xgb_fea(train_dir,ncolors,ncolors,npics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = './girl/gray/WechatIMG1286_gray.jpg'\n",
    "preds = test_xgb_fea(test_img, xgb_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred2color(test_img,preds,label_to_color_map,ncolors=16, saveimg = False, savename = 'test.jpg'):\n",
    "    l_test, a_test, b_test = load_image(test_img)\n",
    "    preds = preds.reshape(h,w)\n",
    "    print(w,h)\n",
    "    colors_present = [i for i in range(ncolors)]\n",
    "    output_a = np.zeros((h,w))\n",
    "    output_b = np.zeros((h,w))\n",
    "    output_l = l_test.reshape((h,w))\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            a,b = label_to_color_map[colors_present[int(preds[i,j])]]\n",
    "            output_a[i,j] = a\n",
    "            output_b[i,j] = b\n",
    "    print(output_a.shape,output_b.shape,output_l.shape)\n",
    "    output_img = cv2.cvtColor(cv2.merge(( np.uint8(output_l), np.uint8(output_a), np.uint8(output_b))),\n",
    "                              cv2.COLOR_LAB2RGB)\n",
    "    if saveimg == True:\n",
    "        plt.imsave('./girl/predict/' + savename,output_img)    \n",
    "    return(output_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_img = pred2color(test_img,preds,label_to_color_map,ncolors=ncolors,\n",
    "                        saveimg = False, savename = 'wenzhu.jpg')\n",
    "plt.imshow(output_img)\n",
    "# cv2.imwrite('savename.jpg', output_img )\n",
    "# plt.imsave('./girl/predict/output_img_gile12.jpg',output_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savegray(path, saveimg = False, savename = 'gray.jpg'):\n",
    "    img = cv2.imread(path) \n",
    "    gray = img = cv2.cvtColor( img, cv2.COLOR_RGB2GRAY )\n",
    "    if saveimg == True:\n",
    "        cv2.imwrite(savename, img )\n",
    "    return(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_test = savegray('./girl/WechatIMG1284.jpg', saveimg = True, savename = './girl/gray/WechatIMG1284_gray.jpg')\n",
    "plt.imshow(gray_test)\n",
    "gray_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features(HoG,Daisy)+Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import itertools\n",
    "import numpy as np\n",
    "from scipy.cluster.vq import kmeans,vq\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "import operator\n",
    "from functools import reduce\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "from skimage.feature import hog, daisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage import color \n",
    "def load_image(path):\n",
    "    '''\n",
    "    Read in a file and separate into L*a*b* channels\n",
    "    '''\n",
    "    #read in original image\n",
    "    img = cv2.imread(path) \n",
    "    l, a, b = cv2.split(cv2.cvtColor(img, cv2.COLOR_RGB2LAB))\n",
    "\n",
    "    return l, a, b\n",
    "\n",
    "def quantize_kmeans(a, b,ncolors, npics):\n",
    "    lengthab = len(a) / npics\n",
    "            \n",
    "    # reshape matrix\n",
    "    pixel = np.reshape((cv2.merge((a,b))),(len(a),2)).astype(float)\n",
    "    \n",
    "    # quantization\n",
    "    kmeans = KMeans(n_clusters=ncolors) \n",
    "    label=kmeans.fit(pixel)\n",
    "    return label.labels_\n",
    "\n",
    "def label_to_color_map_fun(a,b,ncolors):\n",
    "    w,h = np.shape(a)\n",
    "    pixel = np.reshape((cv2.merge((a,b))),(w * h,2)).astype(float)\n",
    "    centroids,_ = kmeans(pixel,ncolors)\n",
    "    color_to_label_map = {c:i for i,c in enumerate([tuple(i) for i in centroids])}\n",
    "    label_to_color_map = dict(zip(color_to_label_map.values(),color_to_label_map.keys()))\n",
    "    return label_to_color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb(files,ncolors,num_class, npics):\n",
    "    \n",
    "    kmap_a=np.array([])\n",
    "    kmap_b=np.array([])\n",
    "    for f in files:\n",
    "        _,a,b = load_image(f)\n",
    "        kmap_a = np.concatenate([kmap_a, a.flatten()])\n",
    "        kmap_b = np.concatenate([kmap_b, b.flatten()])\n",
    "    w,h = np.shape(a)\n",
    "    label=quantize_kmeans(kmap_a, kmap_b, ncolors, npics)\n",
    "    \n",
    "    pixel=[]\n",
    "    for f in files:\n",
    "        l, a, b = load_image(f)\n",
    "        this_pixel = l.reshape(1,w*h).tolist()\n",
    "        pixel.append(this_pixel[0])\n",
    "\n",
    "    pixel = reduce(operator.add, pixel)\n",
    "\n",
    "    pixel_mat = np.array(pixel).reshape(npics*w*h,1)\n",
    "\n",
    "    dtrain = xgb.DMatrix(pixel_mat, label=label)\n",
    "    param = {'max_depth':10, 'eta':0.1, 'silent':1, 'objective':'multi:softmax', 'num_class':num_class}\n",
    "    num_round = 10\n",
    "    print('Begin xgb training')\n",
    "    bst = xgb.train(param, dtrain, num_round)\n",
    "    return bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(file):\n",
    "    test_color = Image.open(file,'r')\n",
    "    test_color = test_color.convert('L') #makes it greyscale\n",
    "    test_gray = np.asarray(test_color.getdata(),dtype=np.float64).reshape((test_color.size[1],test_color.size[0]))\n",
    "    test_gray = np.asarray(test_gray,dtype=np.uint8) #if values still in range 0-255! \n",
    "    test_gray = Image.fromarray(test_gray,mode='L')\n",
    "    \n",
    "    # l(256,256)\n",
    "    l, a, b = load_image(file)\n",
    "    w,h = np.shape(a)\n",
    "    # hog(256,256)\n",
    "    fd, hog_image = hog(test_gray, orientations=8, pixels_per_cell=(16, 16),\n",
    "                        cells_per_block=(1, 1), visualise=True)\n",
    "    # daisy(256,256,3)\n",
    "    descs, descs_img = daisy(test_gray, step=180, radius=58, rings=2, histograms=6,\n",
    "                             orientations=8, visualize=True)\n",
    "    feature = np.zeros((256*256,5))\n",
    "    feature[:,0] = hog_image.reshape(1,256*256)[0]\n",
    "    feature[:,1] = descs_img[:,:,0].reshape(1,256*256)[0]\n",
    "    feature[:,2] = descs_img[:,:,1].reshape(1,256*256)[0]\n",
    "    feature[:,3] = descs_img[:,:,2].reshape(1,256*256)[0]\n",
    "    feature[:,4] = l.reshape(1,256*256)[0]\n",
    "    \n",
    "    return(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_fea(files,ncolors,num_class, npics):\n",
    "    \n",
    "    kmap_a=np.array([])\n",
    "    kmap_b=np.array([])\n",
    "    \n",
    "\n",
    "    for f in files:\n",
    "        _,a,b = load_image(f)\n",
    "        kmap_a = np.concatenate([kmap_a, a.flatten()])\n",
    "        kmap_b = np.concatenate([kmap_b, b.flatten()])\n",
    "\n",
    "    label=quantize_kmeans(kmap_a, kmap_b, ncolors, npics)\n",
    "    w,h = np.shape(a)\n",
    "        \n",
    "    pixel_feature = np.zeros(shape=(w*h*npics,5))\n",
    "    \n",
    "\n",
    "    \n",
    "    for ind,f in enumerate(files):\n",
    "        feature = get_feature(f)\n",
    "        pixel_feature[(w*h*ind):(w*h*(ind+1)),:] = feature\n",
    "\n",
    "    dtrain = xgb.DMatrix(pixel_feature, label=label)\n",
    "    param = {'max_depth':10, 'eta':0.1, 'silent':1, 'objective':'multi:softmax', 'num_class':num_class}\n",
    "    num_round = 10\n",
    "    print('Begin xgb training')\n",
    "    bst = xgb.train(param, dtrain, num_round)\n",
    "    return bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_xgb_fea(file,xgb_model):\n",
    "        \n",
    "    pixel_feature = get_feature(file)\n",
    "\n",
    "    dtest=xgb.DMatrix(pixel_feature)\n",
    "    preds = xgb_fit.predict(dtest)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load images\n",
    "folder_dir = './girl/'\n",
    "train_dir = []\n",
    "\n",
    "for filename in os.listdir(folder_dir):\n",
    "    if filename.startswith('.') or \\\n",
    "    filename.startswith('predict') or \\\n",
    "    filename.startswith('gray'): \n",
    "        continue\n",
    "    train_dir.append(folder_dir + filename)\n",
    "\n",
    "# train_dir = ['WechatIMG1667.jpeg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncolors = 16\n",
    "kmap_a=np.array([])\n",
    "kmap_b=np.array([])\n",
    "for f in train_dir:\n",
    "    _,a,b = load_image(f)\n",
    "    kmap_a = np.concatenate([kmap_a, a.flatten()])\n",
    "    kmap_b = np.concatenate([kmap_b, b.flatten()])\n",
    "h,w = np.shape(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npics = len(train_dir) # number of train image\n",
    "kmap_a = kmap_a.reshape(npics*w*h,1)\n",
    "kmap_b = kmap_b.reshape(npics*w*h,1)\n",
    "label_to_color_map = label_to_color_map_fun(kmap_a,kmap_b,ncolors)\n",
    "print(len(label_to_color_map))\n",
    "ncolors = len(label_to_color_map) # update ncolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_fit = train_xgb_fea(train_dir,ncolors,ncolors,npics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = './girl/gray/WechatIMG1286_gray.jpg'\n",
    "preds = test_xgb_fea(test_img, xgb_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred2color(test_img,preds,label_to_color_map,ncolors=16, saveimg = False, savename = 'test.jpg'):\n",
    "    l_test, a_test, b_test = load_image(test_img)\n",
    "    preds = preds.reshape(h,w)\n",
    "    print(w,h)\n",
    "    colors_present = [i for i in range(ncolors)]\n",
    "    output_a = np.zeros((h,w))\n",
    "    output_b = np.zeros((h,w))\n",
    "    output_l = l_test.reshape((h,w))\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            a,b = label_to_color_map[colors_present[int(preds[i,j])]]\n",
    "            output_a[i,j] = a\n",
    "            output_b[i,j] = b\n",
    "    print(output_a.shape,output_b.shape,output_l.shape)\n",
    "    output_img = cv2.cvtColor(cv2.merge(( np.uint8(output_l), np.uint8(output_a), np.uint8(output_b))),\n",
    "                              cv2.COLOR_LAB2RGB)\n",
    "    if saveimg == True:\n",
    "        plt.imsave('./girl/predict/' + savename,output_img)    \n",
    "    return(output_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_img = pred2color(test_img,preds,label_to_color_map,ncolors=ncolors,\n",
    "                        saveimg = False, savename = 'wenzhu.jpg')\n",
    "plt.imshow(output_img)\n",
    "# cv2.imwrite('savename.jpg', output_img )\n",
    "# plt.imsave('./girl/predict/output_img_gile12.jpg',output_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savegray(path, saveimg = False, savename = 'gray.jpg'):\n",
    "    img = cv2.imread(path) \n",
    "    gray = img = cv2.cvtColor( img, cv2.COLOR_RGB2GRAY )\n",
    "    if saveimg == True:\n",
    "        cv2.imwrite(savename, img )\n",
    "    return(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_test = savegray('./girl/WechatIMG1284.jpg', saveimg = True, savename = './girl/gray/WechatIMG1284_gray.jpg')\n",
    "plt.imshow(gray_test)\n",
    "gray_test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
